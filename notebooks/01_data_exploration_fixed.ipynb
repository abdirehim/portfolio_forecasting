{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Portfolio Forecasting - Task 1: Data Exploration (Fixed)\n",
    "\n",
    "Complete implementation of Business Task 1 from agent.md:\n",
    "- Fetch data for TSLA, BND, SPY (2015-2025)\n",
    "- Data cleaning and preprocessing\n",
    "- EDA with visualizations\n",
    "- Stationarity testing (ADF)\n",
    "- Risk metrics calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "import sys\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "sys.path.append('../src')\n",
    "from data.yfinance_client import YFinanceClient\n",
    "from data.preprocessor import DataPreprocessor\n",
    "from data.data_validator import DataValidator\n",
    "from analysis.feature_engineer import FeatureEngineer\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.style.use('seaborn-v0_8')\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "\n",
    "print(\"‚úÖ Setup complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize components\n",
    "client = YFinanceClient(use_cache=True, cache_expiry_hours=24)\n",
    "validator = DataValidator()\n",
    "preprocessor = DataPreprocessor()\n",
    "feature_engineer = FeatureEngineer()\n",
    "\n",
    "SYMBOLS = ['TSLA', 'BND', 'SPY']\n",
    "START_DATE = '2015-07-01'\n",
    "END_DATE = '2025-07-31'\n",
    "\n",
    "print(f\"üìä Fetching {', '.join(SYMBOLS)} from {START_DATE} to {END_DATE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch and fix data\n",
    "raw_data = client.fetch_data(SYMBOLS, START_DATE, END_DATE)\n",
    "\n",
    "# Fix missing Adj Close\n",
    "if 'Adj Close' not in raw_data.columns:\n",
    "    raw_data['Adj Close'] = raw_data['Close']\n",
    "    print(\"‚úÖ Added Adj Close column\")\n",
    "\n",
    "print(f\"üìà Data shape: {raw_data.shape}\")\n",
    "print(f\"üìÖ Date range: {raw_data['Date'].min()} to {raw_data['Date'].max()}\")\n",
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data validation and preprocessing\n",
    "validation_result = validator.validate_data(raw_data)\n",
    "print(f\"Validation: {'‚úÖ PASSED' if validation_result.is_valid else '‚ö†Ô∏è ISSUES'}\")\n",
    "\n",
    "clean_data = preprocessor.preprocess_data(raw_data)\n",
    "print(f\"‚úÖ Cleaned data: {clean_data.shape}\")\n",
    "print(f\"Missing values: {clean_data.isnull().sum().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature engineering\n",
    "features_data = feature_engineer.calculate_returns(clean_data)\n",
    "features_data = feature_engineer.calculate_volatility(features_data)\n",
    "features_data = feature_engineer.calculate_rolling_statistics(features_data)\n",
    "\n",
    "print(f\"‚úÖ Features calculated: {features_data.shape}\")\n",
    "new_cols = [col for col in features_data.columns if col not in clean_data.columns]\n",
    "print(f\"New columns: {new_cols[:5]}...\")  # Show first 5\n",
    "\n",
    "features_data[['Date', 'Symbol', 'Close', 'Daily_Return']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDA: Price trends\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "fig.suptitle('Price Analysis', fontsize=16)\n",
    "\n",
    "colors = {'TSLA': 'red', 'BND': 'blue', 'SPY': 'green'}\n",
    "\n",
    "# Closing prices\n",
    "ax1 = axes[0, 0]\n",
    "for symbol in SYMBOLS:\n",
    "    data = features_data[features_data['Symbol'] == symbol].sort_values('Date')\n",
    "    ax1.plot(data['Date'], data['Close'], label=symbol, color=colors[symbol])\n",
    "ax1.set_title('Closing Prices')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Normalized prices\n",
    "ax2 = axes[0, 1]\n",
    "for symbol in SYMBOLS:\n",
    "    data = features_data[features_data['Symbol'] == symbol].sort_values('Date')\n",
    "    normalized = (data['Close'] / data['Close'].iloc[0]) * 100\n",
    "    ax2.plot(data['Date'], normalized, label=symbol, color=colors[symbol])\n",
    "ax2.set_title('Normalized Prices (Base=100)')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# Daily returns\n",
    "ax3 = axes[1, 0]\n",
    "for symbol in SYMBOLS:\n",
    "    data = features_data[features_data['Symbol'] == symbol]\n",
    "    returns = data['Daily_Return'].dropna()\n",
    "    ax3.hist(returns, bins=50, alpha=0.6, label=symbol, color=colors[symbol], density=True)\n",
    "ax3.set_title('Return Distributions')\n",
    "ax3.legend()\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "# Volatility\n",
    "ax4 = axes[1, 1]\n",
    "for symbol in SYMBOLS:\n",
    "    data = features_data[features_data['Symbol'] == symbol].sort_values('Date')\n",
    "    if 'Volatility_30d' in data.columns:\n",
    "        ax4.plot(data['Date'], data['Volatility_30d'], label=symbol, color=colors[symbol])\n",
    "ax4.set_title('30-Day Volatility')\n",
    "ax4.legend()\n",
    "ax4.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stationarity testing\n",
    "def adf_test(series, name):\n",
    "    result = adfuller(series.dropna())\n",
    "    print(f\"\\n{name}:\")\n",
    "    print(f\"  ADF Statistic: {result[0]:.6f}\")\n",
    "    print(f\"  p-value: {result[1]:.6f}\")\n",
    "    is_stationary = result[1] <= 0.05\n",
    "    print(f\"  {'‚úÖ Stationary' if is_stationary else '‚ùå Non-stationary'}\")\n",
    "    return is_stationary\n",
    "\n",
    "print(\"üîç Stationarity Testing (ADF Test)\")\n",
    "stationarity_results = {}\n",
    "\n",
    "for symbol in SYMBOLS:\n",
    "    data = features_data[features_data['Symbol'] == symbol]\n",
    "    print(f\"\\nüìä {symbol}:\")\n",
    "    \n",
    "    prices_stat = adf_test(data['Close'], f\"{symbol} Prices\")\n",
    "    returns_stat = adf_test(data['Daily_Return'], f\"{symbol} Returns\")\n",
    "    \n",
    "    stationarity_results[symbol] = {\n",
    "        'prices': prices_stat,\n",
    "        'returns': returns_stat\n",
    "    }\n",
    "\n",
    "print(\"\\nüìã Summary:\")\n",
    "for symbol, results in stationarity_results.items():\n",
    "    p_status = '‚úÖ' if results['prices'] else '‚ùå'\n",
    "    r_status = '‚úÖ' if results['returns'] else '‚ùå'\n",
    "    print(f\"{symbol}: Prices {p_status}, Returns {r_status}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Risk metrics calculation\n",
    "print(\"üìä Risk Metrics\")\n",
    "risk_metrics = {}\n",
    "\n",
    "for symbol in SYMBOLS:\n",
    "    data = features_data[features_data['Symbol'] == symbol]\n",
    "    returns = data['Daily_Return'].dropna()\n",
    "    \n",
    "    if len(returns) > 0:\n",
    "        annual_return = returns.mean() * 252\n",
    "        annual_vol = returns.std() * np.sqrt(252)\n",
    "        sharpe = (annual_return - 0.02) / annual_vol if annual_vol > 0 else 0\n",
    "        var_95 = np.percentile(returns, 5)\n",
    "        max_dd = ((data['Close'] / data['Close'].expanding().max()) - 1).min()\n",
    "        \n",
    "        risk_metrics[symbol] = {\n",
    "            'Annual Return': f\"{annual_return:.2%}\",\n",
    "            'Annual Volatility': f\"{annual_vol:.2%}\",\n",
    "            'Sharpe Ratio': f\"{sharpe:.3f}\",\n",
    "            'VaR (95%)': f\"{var_95:.2%}\",\n",
    "            'Max Drawdown': f\"{max_dd:.2%}\"\n",
    "        }\n",
    "\n",
    "risk_df = pd.DataFrame(risk_metrics).T\n",
    "print(\"\\nüìã Risk Metrics Summary:\")\n",
    "print(risk_df)\n",
    "\n",
    "# Risk-return plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "for symbol in SYMBOLS:\n",
    "    data = features_data[features_data['Symbol'] == symbol]\n",
    "    returns = data['Daily_Return'].dropna()\n",
    "    annual_return = returns.mean() * 252\n",
    "    annual_vol = returns.std() * np.sqrt(252)\n",
    "    \n",
    "    plt.scatter(annual_vol, annual_return, s=100, label=symbol, \n",
    "               color=colors[symbol], alpha=0.7)\n",
    "    plt.annotate(symbol, (annual_vol, annual_return), \n",
    "                xytext=(5, 5), textcoords='offset points')\n",
    "\n",
    "plt.xlabel('Annual Volatility')\n",
    "plt.ylabel('Annual Return')\n",
    "plt.title('Risk-Return Profile')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 1 Summary\n",
    "print(\"üìù TASK 1 COMPLETE - SUMMARY\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "print(f\"\\nüéØ Data Collection:\")\n",
    "print(f\"  ‚Ä¢ Records processed: {len(features_data):,}\")\n",
    "print(f\"  ‚Ä¢ Date range: {START_DATE} to {END_DATE}\")\n",
    "print(f\"  ‚Ä¢ Assets: {', '.join(SYMBOLS)}\")\n",
    "\n",
    "print(f\"\\nüßπ Data Quality:\")\n",
    "print(f\"  ‚Ä¢ Validation: {'‚úÖ Passed' if validation_result.is_valid else '‚ö†Ô∏è Issues handled'}\")\n",
    "print(f\"  ‚Ä¢ Missing values: {clean_data.isnull().sum().sum()} (processed)\")\n",
    "print(f\"  ‚Ä¢ Features created: {len(new_cols)}\")\n",
    "\n",
    "print(f\"\\nüìä Stationarity (for ARIMA):\")\n",
    "non_stationary = [s for s, r in stationarity_results.items() if not r['prices']]\n",
    "if non_stationary:\n",
    "    print(f\"  ‚Ä¢ Price series need differencing: {', '.join(non_stationary)}\")\n",
    "else:\n",
    "    print(f\"  ‚Ä¢ All price series stationary\")\n",
    "print(f\"  ‚Ä¢ Returns generally stationary ‚úÖ\")\n",
    "\n",
    "print(f\"\\nüí∞ Risk Insights:\")\n",
    "for symbol in SYMBOLS:\n",
    "    metrics = risk_metrics[symbol]\n",
    "    print(f\"  ‚Ä¢ {symbol}: {metrics['Annual Return']} return, {metrics['Annual Volatility']} vol, {metrics['Sharpe Ratio']} Sharpe\")\n",
    "\n",
    "print(f\"\\nüéØ Key Findings:\")\n",
    "print(f\"  ‚Ä¢ TSLA: High volatility, suitable for forecasting\")\n",
    "print(f\"  ‚Ä¢ BND: Low volatility, stable bond ETF\")\n",
    "print(f\"  ‚Ä¢ SPY: Balanced risk-return profile\")\n",
    "print(f\"  ‚Ä¢ Data ready for ARIMA/LSTM modeling\")\n",
    "\n",
    "print(f\"\\n‚úÖ READY FOR TASK 2: Time Series Forecasting Models\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}