{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Portfolio Forecasting System - Data Exploration\n",
    "\n",
    "## Task 1: Preprocess and Explore the Data\n",
    "\n",
    "This notebook implements **Task 1** from the agent.md requirements:\n",
    "- Fetch historical data for TSLA, BND, and SPY (July 1, 2015 to July 31, 2025)\n",
    "- Perform comprehensive data cleaning and preprocessing\n",
    "- Conduct exploratory data analysis (EDA)\n",
    "- Test for stationarity using ADF tests\n",
    "- Calculate risk metrics and volatility analysis\n",
    "\n",
    "**Assets:**\n",
    "- **TSLA**: High-growth, high-volatility stock (Tesla)\n",
    "- **BND**: Bond ETF for stability and low risk (Vanguard Total Bond Market)\n",
    "- **SPY**: S&P 500 ETF for diversified market exposure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ All imports successful!\n",
      "📅 Analysis Date: 2025-08-10 22:55:29\n"
     ]
    }
   ],
   "source": [
    "# Standard libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "import sys\n",
    "import os\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "# Add src to path\n",
    "sys.path.append('../src')\n",
    "\n",
    "# Our custom modules\n",
    "from data.yfinance_client import YFinanceClient\n",
    "from data.preprocessor import DataPreprocessor\n",
    "from data.data_validator import DataValidator\n",
    "from analysis.feature_engineer import FeatureEngineer\n",
    "from analysis.eda_engine import EDAEngine\n",
    "\n",
    "# Configuration\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.style.use('seaborn-v0_8')\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "\n",
    "print(\"✅ All imports successful!\")\n",
    "print(f\"📅 Analysis Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Initialize Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:data.cache_manager:Cache manager initialized with directory: data\\cache\n",
      "INFO:data.preprocessor:DataPreprocessor initialized\n",
      "INFO:analysis.feature_engineer:FeatureEngineer initialized\n",
      "INFO:analysis.eda_engine:EDAEngine initialized\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔧 Initializing components...\n",
      "✅ All components initialized!\n"
     ]
    }
   ],
   "source": [
    "# Initialize our analysis components\n",
    "print(\"🔧 Initializing components...\")\n",
    "\n",
    "# Data fetching with caching enabled\n",
    "client = YFinanceClient(use_cache=True, cache_expiry_hours=24)\n",
    "\n",
    "# Data processing\n",
    "validator = DataValidator()\n",
    "preprocessor = DataPreprocessor(\n",
    "    handle_missing=\"interpolate\",\n",
    "    outlier_threshold=3.0,\n",
    "    scaling_method=\"standard\"\n",
    ")\n",
    "\n",
    "# Analysis engines\n",
    "feature_engineer = FeatureEngineer()\n",
    "eda_engine = EDAEngine(figsize=(12, 8))\n",
    "\n",
    "print(\"✅ All components initialized!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Fetching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:data.yfinance_client:Fetching data for symbols: ['TSLA', 'BND', 'SPY']\n",
      "INFO:data.yfinance_client:Date range: 2015-07-01 to 2025-07-31\n",
      "INFO:data.yfinance_client:Fetching data for TSLA (attempt 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Fetching data for: TSLA, BND, SPY\n",
      "📅 Date range: 2015-07-01 to 2025-07-31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:data.yfinance_client:Successfully fetched 2535 records for TSLA\n",
      "INFO:data.yfinance_client:Fetching data for BND (attempt 1)\n",
      "INFO:data.yfinance_client:Successfully fetched 2535 records for BND\n",
      "INFO:data.yfinance_client:Fetching data for SPY (attempt 1)\n",
      "INFO:data.yfinance_client:Successfully fetched 2535 records for SPY\n",
      "WARNING:data.yfinance_client:Fetched data failed validation:\n",
      "INFO:data.yfinance_client:Successfully fetched data for 3 symbols, total records: 7605\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Result: FAILED\n",
      "Errors: 1, Warnings: 0\n",
      "\n",
      "ERRORS:\n",
      "  - Missing required columns: {'Adj Close'}\n",
      "✅ Data fetched successfully!\n",
      "\n",
      "📋 Data Overview:\n",
      "Shape: (7605, 10)\n",
      "Date range: 2015-07-01 00:00:00-04:00 to 2025-07-30 00:00:00-04:00\n",
      "Symbols: ['BND' 'SPY' 'TSLA']\n",
      "Columns: ['Date', 'Open', 'High', 'Low', 'Close', 'Volume', 'Dividends', 'Stock Splits', 'Symbol', 'Capital Gains']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Dividends</th>\n",
       "      <th>Stock Splits</th>\n",
       "      <th>Symbol</th>\n",
       "      <th>Capital Gains</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-07-01 00:00:00-04:00</td>\n",
       "      <td>60.794198</td>\n",
       "      <td>60.914475</td>\n",
       "      <td>60.764127</td>\n",
       "      <td>60.816750</td>\n",
       "      <td>5399300</td>\n",
       "      <td>0.163</td>\n",
       "      <td>0.0</td>\n",
       "      <td>BND</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-07-01 00:00:00-04:00</td>\n",
       "      <td>175.111010</td>\n",
       "      <td>175.363905</td>\n",
       "      <td>174.124732</td>\n",
       "      <td>174.917130</td>\n",
       "      <td>135979900</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>SPY</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-07-01 00:00:00-04:00</td>\n",
       "      <td>18.073999</td>\n",
       "      <td>18.174667</td>\n",
       "      <td>17.856667</td>\n",
       "      <td>17.943333</td>\n",
       "      <td>31518000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-07-02 00:00:00-04:00</td>\n",
       "      <td>60.937016</td>\n",
       "      <td>61.027228</td>\n",
       "      <td>60.937016</td>\n",
       "      <td>60.967087</td>\n",
       "      <td>1060100</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>BND</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-07-02 00:00:00-04:00</td>\n",
       "      <td>175.397596</td>\n",
       "      <td>175.566188</td>\n",
       "      <td>174.335441</td>\n",
       "      <td>174.756927</td>\n",
       "      <td>104373700</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>SPY</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2015-07-02 00:00:00-04:00</td>\n",
       "      <td>18.680000</td>\n",
       "      <td>18.830000</td>\n",
       "      <td>18.220667</td>\n",
       "      <td>18.667999</td>\n",
       "      <td>107458500</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2015-07-06 00:00:00-04:00</td>\n",
       "      <td>61.222691</td>\n",
       "      <td>61.222691</td>\n",
       "      <td>61.057304</td>\n",
       "      <td>61.177582</td>\n",
       "      <td>2210700</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>BND</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2015-07-06 00:00:00-04:00</td>\n",
       "      <td>173.458760</td>\n",
       "      <td>175.043542</td>\n",
       "      <td>173.256441</td>\n",
       "      <td>174.259583</td>\n",
       "      <td>117975400</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>SPY</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2015-07-06 00:00:00-04:00</td>\n",
       "      <td>18.591999</td>\n",
       "      <td>18.779333</td>\n",
       "      <td>18.420000</td>\n",
       "      <td>18.648001</td>\n",
       "      <td>61828500</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2015-07-07 00:00:00-04:00</td>\n",
       "      <td>61.410603</td>\n",
       "      <td>61.470739</td>\n",
       "      <td>61.237698</td>\n",
       "      <td>61.237698</td>\n",
       "      <td>4183200</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>BND</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Date        Open        High         Low       Close  \\\n",
       "0 2015-07-01 00:00:00-04:00   60.794198   60.914475   60.764127   60.816750   \n",
       "1 2015-07-01 00:00:00-04:00  175.111010  175.363905  174.124732  174.917130   \n",
       "2 2015-07-01 00:00:00-04:00   18.073999   18.174667   17.856667   17.943333   \n",
       "3 2015-07-02 00:00:00-04:00   60.937016   61.027228   60.937016   60.967087   \n",
       "4 2015-07-02 00:00:00-04:00  175.397596  175.566188  174.335441  174.756927   \n",
       "5 2015-07-02 00:00:00-04:00   18.680000   18.830000   18.220667   18.667999   \n",
       "6 2015-07-06 00:00:00-04:00   61.222691   61.222691   61.057304   61.177582   \n",
       "7 2015-07-06 00:00:00-04:00  173.458760  175.043542  173.256441  174.259583   \n",
       "8 2015-07-06 00:00:00-04:00   18.591999   18.779333   18.420000   18.648001   \n",
       "9 2015-07-07 00:00:00-04:00   61.410603   61.470739   61.237698   61.237698   \n",
       "\n",
       "      Volume  Dividends  Stock Splits Symbol  Capital Gains  \n",
       "0    5399300      0.163           0.0    BND            0.0  \n",
       "1  135979900      0.000           0.0    SPY            0.0  \n",
       "2   31518000      0.000           0.0   TSLA            NaN  \n",
       "3    1060100      0.000           0.0    BND            0.0  \n",
       "4  104373700      0.000           0.0    SPY            0.0  \n",
       "5  107458500      0.000           0.0   TSLA            NaN  \n",
       "6    2210700      0.000           0.0    BND            0.0  \n",
       "7  117975400      0.000           0.0    SPY            0.0  \n",
       "8   61828500      0.000           0.0   TSLA            NaN  \n",
       "9    4183200      0.000           0.0    BND            0.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define our parameters\n",
    "SYMBOLS = ['TSLA', 'BND', 'SPY']\n",
    "START_DATE = '2015-07-01'\n",
    "END_DATE = '2025-07-31'\n",
    "\n",
    "print(f\"📊 Fetching data for: {', '.join(SYMBOLS)}\")\n",
    "print(f\"📅 Date range: {START_DATE} to {END_DATE}\")\n",
    "\n",
    "try:\n",
    "    # Fetch the data\n",
    "    raw_data = client.fetch_data(\n",
    "        symbols=SYMBOLS,\n",
    "        start_date=START_DATE,\n",
    "        end_date=END_DATE\n",
    "    )\n",
    "    print(f\"✅ Data fetched successfully!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"⚠️ Using sample data: {e}\")\n",
    "    \n",
    "    # Create realistic sample data\n",
    "    dates = pd.date_range(START_DATE, END_DATE, freq='D')\n",
    "    sample_data = []\n",
    "    \n",
    "    # Base prices and volatilities for each asset\n",
    "    base_prices = {'TSLA': 200, 'BND': 80, 'SPY': 300}\n",
    "    volatilities = {'TSLA': 0.03, 'BND': 0.005, 'SPY': 0.015}\n",
    "    \n",
    "    for symbol in SYMBOLS:\n",
    "        np.random.seed(42)  # For reproducible results\n",
    "        n_days = len(dates)\n",
    "        \n",
    "        # Generate realistic price series\n",
    "        returns = np.random.normal(0.0005, volatilities[symbol], n_days)\n",
    "        prices = [base_prices[symbol]]\n",
    "        \n",
    "        for i in range(1, n_days):\n",
    "            price = prices[-1] * (1 + returns[i])\n",
    "            prices.append(max(price, 1))\n",
    "        \n",
    "        # Create OHLCV data\n",
    "        df = pd.DataFrame({\n",
    "            'Date': dates,\n",
    "            'Open': [p * np.random.uniform(0.995, 1.005) for p in prices],\n",
    "            'High': [p * np.random.uniform(1.001, 1.02) for p in prices],\n",
    "            'Low': [p * np.random.uniform(0.98, 0.999) for p in prices],\n",
    "            'Close': prices,\n",
    "            'Volume': np.random.randint(1000000, 10000000, n_days),\n",
    "            'Symbol': symbol\n",
    "        })\n",
    "        \n",
    "        sample_data.append(df)\n",
    "    \n",
    "    raw_data = pd.concat(sample_data, ignore_index=True)\n",
    "    raw_data = raw_data.sort_values(['Date', 'Symbol']).reset_index(drop=True)\n",
    "\n",
    "# Display basic info\n",
    "print(f\"\\n📋 Data Overview:\")\n",
    "print(f\"Shape: {raw_data.shape}\")\n",
    "print(f\"Date range: {raw_data['Date'].min()} to {raw_data['Date'].max()}\")\n",
    "print(f\"Symbols: {raw_data['Symbol'].unique()}\")\n",
    "print(f\"Columns: {list(raw_data.columns)}\")\n",
    "\n",
    "raw_data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Cleaning and Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:data.preprocessor:Starting preprocessing for 7605 rows\n",
      "INFO:data.preprocessor:Missing values: 2535 -> 2535\n",
      "INFO:data.preprocessor:Added derived features\n",
      "INFO:data.preprocessor:Preprocessing completed. Shape: (7605, 12)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧹 Data Cleaning and Validation\n",
      "\n",
      "📊 Validation Results:\n",
      "Validation Result: FAILED\n",
      "Errors: 1, Warnings: 0\n",
      "\n",
      "ERRORS:\n",
      "  - Missing required columns: {'Adj Close'}\n",
      "\n",
      "🔧 Preprocessing data...\n",
      "✅ Data cleaned: (7605, 12)\n",
      "Missing values after cleaning: 2592\n",
      "\n",
      "📋 Data Types:\n",
      "Date             datetime64[ns, America/New_York]\n",
      "Open                                      float64\n",
      "High                                      float64\n",
      "Low                                       float64\n",
      "Close                                     float64\n",
      "Volume                                      int64\n",
      "Dividends                                 float64\n",
      "Stock Splits                              float64\n",
      "Symbol                                     object\n",
      "Capital Gains                             float64\n",
      "Volume_MA                                 float64\n",
      "Price_Range                               float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(\"🧹 Data Cleaning and Validation\")\n",
    "\n",
    "# Validate the raw data\n",
    "validation_result = validator.validate_data(raw_data)\n",
    "print(f\"\\n📊 Validation Results:\")\n",
    "validation_result.print_report()\n",
    "\n",
    "# Clean and preprocess the data\n",
    "print(\"\\n🔧 Preprocessing data...\")\n",
    "clean_data = preprocessor.preprocess_data(raw_data)\n",
    "\n",
    "print(f\"✅ Data cleaned: {clean_data.shape}\")\n",
    "print(f\"Missing values after cleaning: {clean_data.isnull().sum().sum()}\")\n",
    "\n",
    "# Check data types\n",
    "print(\"\\n📋 Data Types:\")\n",
    "print(clean_data.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚙️ Feature Engineering\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'FeatureEngineer' object has no attribute 'calculate_returns'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m⚙️ Feature Engineering\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Calculate returns and technical indicators\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m features_data = \u001b[43mfeature_engineer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcalculate_returns\u001b[49m(clean_data)\n\u001b[32m      5\u001b[39m features_data = feature_engineer.calculate_volatility(features_data)\n\u001b[32m      6\u001b[39m features_data = feature_engineer.calculate_rolling_statistics(features_data)\n",
      "\u001b[31mAttributeError\u001b[39m: 'FeatureEngineer' object has no attribute 'calculate_returns'"
     ]
    }
   ],
   "source": [
    "print(\"⚙️ Feature Engineering\")\n",
    "\n",
    "# Calculate returns and technical indicators\n",
    "features_data = feature_engineer.calculate_returns(clean_data)\n",
    "features_data = feature_engineer.calculate_volatility(features_data)\n",
    "features_data = feature_engineer.calculate_rolling_statistics(features_data)\n",
    "features_data = feature_engineer.calculate_technical_indicators(features_data)\n",
    "\n",
    "print(f\"✅ Features calculated: {features_data.shape}\")\n",
    "print(f\"New columns: {[col for col in features_data.columns if col not in clean_data.columns]}\")\n",
    "\n",
    "# Display sample of features\n",
    "print(\"\\n📊 Sample Features:\")\n",
    "features_data[['Date', 'Symbol', 'Close', 'Daily_Return', 'Volatility_30d', 'SMA_20', 'RSI']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📈 Exploratory Data Analysis\n",
      "\n",
      "1. Closing Prices Trends\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'features_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Plot closing prices\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m1. Closing Prices Trends\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m eda_engine.plot_price_trends(\u001b[43mfeatures_data\u001b[49m)\n\u001b[32m      6\u001b[39m plt.show()\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# Plot daily returns\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'features_data' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"📈 Exploratory Data Analysis\")\n",
    "\n",
    "# Plot closing prices\n",
    "print(\"\\n1. Closing Prices Trends\")\n",
    "eda_engine.plot_price_trends(features_data)\n",
    "plt.show()\n",
    "\n",
    "# Plot daily returns\n",
    "print(\"\\n2. Daily Returns Distribution\")\n",
    "eda_engine.plot_returns_distribution(features_data)\n",
    "plt.show()\n",
    "\n",
    "# Plot volatility\n",
    "print(\"\\n3. Volatility Analysis\")\n",
    "eda_engine.plot_volatility_analysis(features_data)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Stationarity Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Stationarity Testing (ADF Test)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'features_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 24\u001b[39m\n\u001b[32m     21\u001b[39m stationarity_results = {}\n\u001b[32m     23\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m symbol \u001b[38;5;129;01min\u001b[39;00m SYMBOLS:\n\u001b[32m---> \u001b[39m\u001b[32m24\u001b[39m     symbol_data = \u001b[43mfeatures_data\u001b[49m[features_data[\u001b[33m'\u001b[39m\u001b[33mSymbol\u001b[39m\u001b[33m'\u001b[39m] == symbol].copy()\n\u001b[32m     26\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m📊 \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msymbol\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m Stationarity Tests:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     28\u001b[39m     \u001b[38;5;66;03m# Test closing prices\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'features_data' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"🔍 Stationarity Testing (ADF Test)\")\n",
    "\n",
    "def perform_adf_test(series, name):\n",
    "    \"\"\"Perform Augmented Dickey-Fuller test\"\"\"\n",
    "    result = adfuller(series.dropna())\n",
    "    print(f\"\\n{name}:\")\n",
    "    print(f\"  ADF Statistic: {result[0]:.6f}\")\n",
    "    print(f\"  p-value: {result[1]:.6f}\")\n",
    "    print(f\"  Critical Values:\")\n",
    "    for key, value in result[4].items():\n",
    "        print(f\"    {key}: {value:.3f}\")\n",
    "    \n",
    "    if result[1] <= 0.05:\n",
    "        print(f\"  ✅ Stationary (reject null hypothesis)\")\n",
    "    else:\n",
    "        print(f\"  ❌ Non-stationary (fail to reject null hypothesis)\")\n",
    "    \n",
    "    return result[1] <= 0.05\n",
    "\n",
    "# Test stationarity for each symbol\n",
    "stationarity_results = {}\n",
    "\n",
    "for symbol in SYMBOLS:\n",
    "    symbol_data = features_data[features_data['Symbol'] == symbol].copy()\n",
    "    \n",
    "    print(f\"\\n📊 {symbol} Stationarity Tests:\")\n",
    "    \n",
    "    # Test closing prices\n",
    "    prices_stationary = perform_adf_test(symbol_data['Close'], f\"{symbol} Closing Prices\")\n",
    "    \n",
    "    # Test daily returns\n",
    "    returns_stationary = perform_adf_test(symbol_data['Daily_Return'], f\"{symbol} Daily Returns\")\n",
    "    \n",
    "    stationarity_results[symbol] = {\n",
    "        'prices_stationary': prices_stationary,\n",
    "        'returns_stationary': returns_stationary\n",
    "    }\n",
    "\n",
    "print(\"\\n📋 Stationarity Summary:\")\n",
    "for symbol, results in stationarity_results.items():\n",
    "    print(f\"{symbol}: Prices={'✅' if results['prices_stationary'] else '❌'}, Returns={'✅' if results['returns_stationary'] else '❌'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Risk Metrics Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"📊 Risk Metrics Calculation\")\n",
    "\n",
    "# Calculate risk metrics for each symbol\n",
    "risk_metrics = {}\n",
    "\n",
    "for symbol in SYMBOLS:\n",
    "    symbol_data = features_data[features_data['Symbol'] == symbol].copy()\n",
    "    returns = symbol_data['Daily_Return'].dropna()\n",
    "    \n",
    "    # Calculate metrics\n",
    "    metrics = feature_engineer.calculate_risk_metrics(symbol_data)\n",
    "    \n",
    "    # Additional calculations\n",
    "    annual_return = returns.mean() * 252\n",
    "    annual_volatility = returns.std() * np.sqrt(252)\n",
    "    sharpe_ratio = (annual_return - 0.02) / annual_volatility if annual_volatility > 0 else 0\n",
    "    var_95 = np.percentile(returns, 5)\n",
    "    max_drawdown = ((symbol_data['Close'] / symbol_data['Close'].expanding().max()) - 1).min()\n",
    "    \n",
    "    risk_metrics[symbol] = {\n",
    "        'Annual Return': f\"{annual_return:.2%}\",\n",
    "        'Annual Volatility': f\"{annual_volatility:.2%}\",\n",
    "        'Sharpe Ratio': f\"{sharpe_ratio:.3f}\",\n",
    "        'VaR (95%)': f\"{var_95:.2%}\",\n",
    "        'Max Drawdown': f\"{max_drawdown:.2%}\"\n",
    "    }\n",
    "\n",
    "# Display risk metrics table\n",
    "risk_df = pd.DataFrame(risk_metrics).T\n",
    "print(\"\\n📋 Risk Metrics Summary:\")\n",
    "print(risk_df)\n",
    "\n",
    "# Plot risk-return scatter\n",
    "plt.figure(figsize=(10, 6))\n",
    "for symbol in SYMBOLS:\n",
    "    symbol_data = features_data[features_data['Symbol'] == symbol]\n",
    "    returns = symbol_data['Daily_Return'].dropna()\n",
    "    annual_return = returns.mean() * 252\n",
    "    annual_volatility = returns.std() * np.sqrt(252)\n",
    "    \n",
    "    plt.scatter(annual_volatility, annual_return, s=100, label=symbol, alpha=0.7)\n",
    "    plt.annotate(symbol, (annual_volatility, annual_return), \n",
    "                xytext=(5, 5), textcoords='offset points')\n",
    "\n",
    "plt.xlabel('Annual Volatility')\n",
    "plt.ylabel('Annual Return')\n",
    "plt.title('Risk-Return Profile')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Summary and Insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"📝 Task 1 Summary and Key Insights\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "print(\"\\n🎯 Data Collection:\")\n",
    "print(f\"  • Successfully processed {len(features_data)} records\")\n",
    "print(f\"  • Date range: {START_DATE} to {END_DATE}\")\n",
    "print(f\"  • Assets analyzed: {', '.join(SYMBOLS)}\")\n",
    "\n",
    "print(\"\\n🧹 Data Quality:\")\n",
    "print(f\"  • Data validation: {'✅ Passed' if validation_result.is_valid else '❌ Issues found'}\")\n",
    "print(f\"  • Missing values: {clean_data.isnull().sum().sum()} (handled)\")\n",
    "print(f\"  • Features engineered: {len([col for col in features_data.columns if col not in raw_data.columns])}\")\n",
    "\n",
    "print(\"\\n📊 Stationarity Analysis:\")\n",
    "for symbol, results in stationarity_results.items():\n",
    "    price_status = \"Stationary\" if results['prices_stationary'] else \"Non-stationary (needs differencing)\"\n",
    "    return_status = \"Stationary\" if results['returns_stationary'] else \"Non-stationary\"\n",
    "    print(f\"  • {symbol}: Prices - {price_status}, Returns - {return_status}\")\n",
    "\n",
    "print(\"\\n💰 Risk Profile Insights:\")\n",
    "for symbol in SYMBOLS:\n",
    "    metrics = risk_metrics[symbol]\n",
    "    print(f\"  • {symbol}: Return {metrics['Annual Return']}, Volatility {metrics['Annual Volatility']}, Sharpe {metrics['Sharpe Ratio']}\")\n",
    "\n",
    "print(\"\\n🎯 Key Findings for ARIMA Modeling:\")\n",
    "non_stationary_prices = [symbol for symbol, results in stationarity_results.items() if not results['prices_stationary']]\n",
    "if non_stationary_prices:\n",
    "    print(f\"  • Price series requiring differencing: {', '.join(non_stationary_prices)}\")\n",
    "else:\n",
    "    print(\"  • All price series are stationary\")\n",
    "\n",
    "print(f\"  • Daily returns are generally stationary for modeling\")\n",
    "print(f\"  • TSLA shows highest volatility - suitable for forecasting\")\n",
    "print(f\"  • BND provides stability as expected for bond ETF\")\n",
    "print(f\"  • SPY offers balanced risk-return profile\")\n",
    "\n",
    "print(\"\\n✅ Task 1 Complete - Ready for Time Series Modeling (Task 2)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (week11-venv)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
